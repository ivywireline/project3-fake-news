\documentclass[10pt,letterpaper]{article}
\usepackage[latin1]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage[margin=1in]{geometry}
\usepackage{listings}
\usepackage{float}
\usepackage{fancyhdr}
\pagestyle{fancy}
\lhead{\today}
\chead{Project 2}
\rhead{Tan, Zhou}
%\usepackage[margin=1in]{geometry}
\usepackage{color} %red, green, blue, yellow, cyan, magenta, black, white
\definecolor{mygreen}{RGB}{28,172,0} % color values Red, Green, Blue
\definecolor{mylilas}{RGB}{170,55,241}

\newcommand{\ssbracket}[2]{#1^{(#2)}}

\author{Hao Hui Tan(999741711, tanstev1)\\Kyle Zhou (1000959732, zhoukyle)}
\title{CSC411H1S Project 3}
\begin{document}
	\lstset{language=Python,%
		%basicstyle=\color{red},
		breaklines=true,%
		%morekeywords={matlab2tikz},
		keywordstyle=\color{blue},%
		morekeywords=[2]{1}, keywordstyle=[2]{\color{black}},
		identifierstyle=\color{black},%
		stringstyle=\color{mylilas},
		commentstyle=\color{mygreen},%
		showstringspaces=false,%without this there will be a symbol in the places where there is a space
		numbers=left,%
		numberstyle={\tiny \color{black}},% size of the numbers
		numbersep=9pt, % this defines how far the numbers are from the text
		emph=[1]{for,end,break},emphstyle=[1]\color{red}, %some words to emphasise
		%emph=[2]{word1,word2}, emphstyle=[2]{style},
		caption=\lstname,
	}

	\maketitle
	\newpage
	\begin{enumerate}
		\item %1
		The Real headline data set seems to be larger than the Fake headline data set.
		Most of the headlines for both data sets are in English, but there are some French and Spanish headlines, as well as possibly other languages.

		Fake headlines seem to use ``Trump'' to refer to Donald Trump, while real headlines tend to use ``Donald Trump.''
		Fake headlines also tend to use more sensational or inflammatory terms such as declaring something ``an hilarious fail,'' or have grammatical mistakes like the aforementioned example.
		Headlines in general are all lowercase with no punctuation.
		However, it seems that the real headlines tend to be truncated, while the fake headlines seem to all have the full text.
		Some of the headlines are also misspelled (e.g. ``x jinpingi'' instead of ``xi jinping'').

		It is difficult to categorize headlines solely based on keywords, since the same word in different contexts could be either sensational, or factual.
		Some useful keywords could be ``racist'' (5 occurrences in fake, 2 occurrences in real), ``hillary,'' (18 occurrences in real, 97 occurrences in fake), and ``rigged'' (3 occurrences in real, 15 occurrences in fake).

		\item %2
		The Naive Bayes algorithm was computed by computing the conditional probability 
		\[
			P(x_i | c) =  \frac{count(x_i = 1, c)}{count(c)}
		\]
		for all $x_i$ in the training set, and for each class $c$ (i.e. ``real'' or ``fake'').
		The actual formula used involves using $m$ and $\hat{p}$ as priors in order to improve the accuracy of our model, since many words only occur once, or a few times.
		Thus, the formula we trained with was
		\[
			P(x_i | c) =  \frac{count(x_i = 1, c) + m\hat{p}}{count(c) + m}
		\]
		
		To predict whether a headline was real or fake, we computed the conditional probability
		\[P(x_1, ..., x_n | c) P(c)\]
		by computing 
		\[\prod_{i = 1}^{n}p(x_i|y=c)\]
		However, since for the less frequent words, $p(x_i|y=c)$ is very small, and multiplying them together may result in underflow, we computed the exponential of the sum of the log probabilities instead.
		Thus, our formula becomes 
		\[
			P(x_1, ..., x_n | c) P(c) = \exp\left(\sum_{i = 1}^{n}\log(P(x_i|y=c))\right)P(c)
		\]
		We then return the class with the highest probability as our prediction.
		
		In order to tune the $m$ and $\hat{p}$ parameters, we trained the model with varying values, with $m \in [1, 20]$ and $p\in [0.1, 1.0]$, with a step of 1 and 0.1, respectively, and found the values that performed best on the validation set.
		
		The performance of the classifier on the training set is 96\%, and the performance on the test set is 85\%
		
		The best params are as follows: \\
		\[m = 2, \hat{p} = 0.2\]
		\\
		The code is included below:
		\begin{lstlisting}
def train_model(real_headlines, fake_headlines, m, p):
    word_list = get_wordlist(real_headlines, fake_headlines)
    real_counts = count_word_occurrance(real_headlines)
    fake_counts = count_word_occurrance(fake_headlines)
    probabilities_real = {}
    probabilities_fake = {}
    for word in word_list:
        # if word in ENGLISH_STOP_WORDS: continue
        if word in real_counts:
            probabilities_real[word] = (real_counts[word] + m * p) / float(len(real_headlines) + m)
        else:
            probabilities_real[word] = (0 + m * p) / float(len(real_headlines) + m)
        if word in fake_counts:
            probabilities_fake[word] = (fake_counts[word] + m * p) / float(len(fake_headlines) + m)
        else:
            probabilities_fake[word] = (0 + m * p) / float(len(fake_headlines) + m)

    return probabilities_real, probabilities_fake, m, p, len(real_headlines), len(fake_headlines), word_list

def predict_model(model, headline):
    probabilities_real, probabilities_fake, m, p, real_count, fake_count, word_list = model
    logprob_real = 0.0
    logprob_fake = 0.0
    real_class_prob = float(real_count) / (real_count + fake_count)
    fake_class_prob = float(fake_count) / (real_count + fake_count)
    headline_split = headline.split(' ')
    for word in word_list:
        # if word in ENGLISH_STOP_WORDS: continue
        if word in headline_split:
            logprob_real += math.log(probabilities_real[word])
            logprob_fake += math.log(probabilities_fake[word])
        else:
            logprob_real += math.log(1 - probabilities_real[word])
            logprob_fake += math.log(1 - probabilities_fake[word])
    real_prob = math.exp(logprob_real) * real_class_prob
    fake_prob = math.exp(logprob_fake) * fake_class_prob
    # print real_prob, fake_prob
    return real_prob > fake_prob

def tune_model(real_training, fake_training, real_validation, fake_validation):
    performance_report = {}
    m = 1
    while m <= 20:
        p = 0.1
        while p <= 1:
            model = train_model(real_training, fake_training, m, p)
            performance = get_performance(model, real_validation, fake_validation)
            print m, p, performance
            performance_report[(m, p)] = performance
            p += 0.1
        m += 1

    print "The m and p value is", max(performance_report, key=performance_report.get)

    return performance_report

def get_performance(model, real, fake):
    correct = 0

    for hl in real:
        if predict_model(model, hl):
            correct += 1

    for hl in fake:
        if not predict_model(model, hl):
            correct += 1

    return float(correct) / (len(real) + len(fake))
		\end{lstlisting}
		\item %3
		\begin{enumerate}
			\item %3a
			The 10 words whose presence most strongly predicts that the news is real
			\begin{enumerate}
				\item trump
				\item donald
				\item to
				\item trumps
				\item in
				\item us
				\item on
				\item of
				\item for
				\item says
			\end{enumerate}
		
			The 10 words whose absence most strongly predicts that the news is real
			\begin{enumerate}
				\item christians
				\item appoint
				\item nevertrump
				\item boycottcomedian
				\item pandering
				\item weld
				\item uneducated
				\item honchos
				\item rep
				\item 8th
			\end{enumerate}
		
			The 10 words whose presence most strongly predicts that the news is fake
			\begin{enumerate}
				\item trump
				\item to
				\item the
				\item donald
				\item in
				\item for
				\item of
				\item a
				\item and
				\item is
			\end{enumerate}
		
			The 10 words whose absence most strongly predicts that the news is fake
			\begin{enumerate}
				\item repeal
				\item friends
				\item union
				\item exposure
				\item resolution
				\item khanfar
				\item rule
				\item jab
				\item rural
				\item expands
			\end{enumerate}
		
			These lists were obtained by finding the words with the highest and lowest conditional probability $P(x|c)$.
			If the conditional probability is high, then if the word is present in the headline, it will not decrease the term $P(x_1, ..., x_n | c)$ as much (since the probability is closer to 1), which means that the final conditional probability will be higher.
			If the conditional probability is low, then if the word is \textit{absent} from the headline, it will also result in a lower penalty than if the probability were higher.
			That's because $1 - P(x_i|c)$ is used instead.
			
			However, due to the addition of the $m$ and $\hat{p}$ values to the equation for $p(x_i|c)$, the bounds on the probability is not 1.0 and 0.0.
			In the case of our optimal values ($m = 2, \hat{p} = 0.2$), the min and max values are  0.00392 and 0.984, respectively.
			Since \(1 - 0.00392 > 0.984\), having a missing word absent is stronger than having a common word present.
			\item %3b
			The following lists have had the stopwords from scikit\_learn excluded
			
			The 10 words whose presence most strongly predicts that the news is real
			\begin{enumerate}
				\item trump
				\item donald
				\item trumps
				\item says
				\item election
				\item clinton
				\item ban
				\item north
				\item korea
				\item president
			\end{enumerate}
		
			The 10 words whose absence most strongly predicts that the news is real
			\begin{enumerate}
				\item backfires
				\item christians
				\item honchos
				\item nevertrump
				\item boycottcomedian
				\item pierson
				\item uneducated
				\item banishment
				\item rep
				\item tanking
			\end{enumerate}
		
			The 10 words whose presence most strongly predicts that the news is fake
			\begin{enumerate}
				\item trump
				\item donald
				\item trumps
				\item says
				\item election
				\item clinton
				\item ban
				\item north
				\item korea
				\item president
			\end{enumerate}
		
			The 10 words whose absence most strongly predicts that the news is fake
			\begin{enumerate}
				\item backfires
				\item christians
				\item honchos
				\item nevertrump
				\item boycottcomedian
				\item pierson
				\item uneducated
				\item banishment
				\item rep
				\item tanking
			\end{enumerate}
			\item %3c
			
		\end{enumerate}
	\item %4
	\item %5
	\item %6
	\begin{enumerate}
		\item %6a
		\item %6b
		\item %6c
	\end{enumerate}
	\item %7
	\begin{enumerate}
		\item %7a
		\item %7b
		\item %7c
	\end{enumerate}
	\item %8
	\begin{enumerate}
		\item %8a
		\item %8b
	\end{enumerate}
	\end{enumerate}
\end{document}
